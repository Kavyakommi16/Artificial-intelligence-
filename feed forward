import numpy as np

class ReLUFeedforwardNN:
    def _init_(self, input_size, hidden_size, output_size):
        # Initialize weights
        self.weights_input_hidden = np.random.rand(input_size, hidden_size)
        self.weights_hidden_output = np.random.rand(hidden_size, output_size)
    
    def relu(self, x):
        return np.maximum(0, x)
    
    def forward(self, x):
        # Forward pass
        hidden_layer = self.relu(np.dot(x, self.weights_input_hidden))
        output_layer = self.relu(np.dot(hidden_layer, self.weights_hidden_output))
        return output_layer

# Example usage
nn_relu = ReLUFeedforwardNN(input_size=3, hidden_size=5, output_size=2)
input_data = np.array([0.1, 0.2, 0.3])
output = nn_relu.forward(input_data)
print("Output with ReLU:", output)
